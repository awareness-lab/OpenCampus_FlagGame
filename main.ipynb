{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe.tasks import python\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(result:mp.tasks.vision.PoseLandmarkerResult, output_image:mp.Image, timestamp_mp:int):\n",
    "    print(f\"pose landmarker result {result}\")\n",
    "\n",
    "#モデルの宣言\n",
    "base_options = python.BaseOptions(model_asset_path=\"pose_landmarker_heavy.task\")\n",
    "running_mode = mp.tasks.vision.RunningMode.LIVE_STREAM\n",
    "options = python.vision.PoseLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=running_mode,\n",
    "    result_callback=print_result,\n",
    "    output_segmentation_masks=True\n",
    ")\n",
    "\n",
    "detector = python.vision.PoseLandmarker.create_from_options(options)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Mediapipeの準備\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    # カメラのキャプチャ準備\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            # カメラからフレームを取得\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            #フレームを反転\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            # フレームをRGBに変換\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Mediapipeを使用して骨格推定を実行\n",
    "            results = pose.process(frame_rgb)\n",
    "\n",
    "            # 骨格推定の結果を描画\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=frame,\n",
    "                    landmark_list=results.pose_landmarks,\n",
    "                    connections=mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2),\n",
    "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(0,0,255), thickness=2))\n",
    "\n",
    "            # 結果を表示\n",
    "            cv2.imshow('MediaPipe Pose', frame)\n",
    "\n",
    "            # 'q'を押すと終了\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    # カメラの解放とウィンドウの破棄\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide 'image_format' with 'data'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ut \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     detection_result \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mut\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     annotated_image \u001b[38;5;241m=\u001b[39m draw_landmarks_on_image(frame\u001b[38;5;241m.\u001b[39mnumpy_view(), detection_result)\n\u001b[1;32m      7\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(annotated_image)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/mediapipe/tasks/python/vision/pose_landmarker.py:449\u001b[0m, in \u001b[0;36mPoseLandmarker.detect_async\u001b[0;34m(self, image, timestamp_ms, image_processing_options)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sends live image data to perform pose landmarks detection.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03mThe results will be available via the \"result_callback\" provided in the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m  pose landmarker has already processed.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m normalized_rect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_normalized_rect(\n\u001b[1;32m    446\u001b[0m     image_processing_options, image, roi_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    447\u001b[0m )\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_live_stream_data({\n\u001b[0;32m--> 449\u001b[0m     _IMAGE_IN_STREAM_NAME: \u001b[43mpacket_creator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mat(\n\u001b[1;32m    450\u001b[0m         timestamp_ms \u001b[38;5;241m*\u001b[39m _MICRO_SECONDS_PER_MILLISECOND\n\u001b[1;32m    451\u001b[0m     ),\n\u001b[1;32m    452\u001b[0m     _NORM_RECT_STREAM_NAME: packet_creator\u001b[38;5;241m.\u001b[39mcreate_proto(\n\u001b[1;32m    453\u001b[0m         normalized_rect\u001b[38;5;241m.\u001b[39mto_pb2()\n\u001b[1;32m    454\u001b[0m     )\u001b[38;5;241m.\u001b[39mat(timestamp_ms \u001b[38;5;241m*\u001b[39m _MICRO_SECONDS_PER_MILLISECOND),\n\u001b[1;32m    455\u001b[0m })\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/mediapipe/python/packet_creator.py:229\u001b[0m, in \u001b[0;36mcreate_image\u001b[0;34m(data, image_format, copy)\u001b[0m\n\u001b[1;32m    226\u001b[0m   \u001b[38;5;66;03m# pylint:enable=protected-access\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m image_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease provide \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mimage_format\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;66;03m# If copy arg is not set, copying the data if it's immutable. Otherwise,\u001b[39;00m\n\u001b[1;32m    231\u001b[0m   \u001b[38;5;66;03m# take a reference of the immutable data to avoid data copy.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide 'image_format' with 'data'."
     ]
    }
   ],
   "source": [
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    ut = time.time()\n",
    "    if ret == True:\n",
    "        detection_result = detector.detect_async(frame, ut)\n",
    "        annotated_image = draw_landmarks_on_image(frame.numpy_view(), detection_result)\n",
    "        cv2.imshow(annotated_image)\n",
    "        #cv2.imshow(\"web cam\", frame)\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
